package org.hyizhou.titaniumstation.ai.llmClient.openRouter;

import com.fasterxml.jackson.annotation.JsonInclude;
import com.fasterxml.jackson.annotation.JsonProperty;
import org.springframework.ai.openai.api.ApiUtils;
import org.springframework.ai.openai.api.OpenAiApi;
import org.springframework.ai.retry.RetryUtils;
import org.springframework.http.ResponseEntity;
import org.springframework.util.Assert;
import org.springframework.web.client.ResponseErrorHandler;
import org.springframework.web.client.RestClient;
import org.springframework.web.reactive.function.client.WebClient;

import java.util.List;

/**
 * openRouter 平台的底层api，其实和openAi的api基本一致，只是多一些参数值
 * @date 2024/5/18
 */
@Deprecated
public class OpenRouterApi extends OpenAiApi {
    private static final String DEFAULT_BASE_URL = "https://openrouter.ai/api";
    private final RestClient restClient;

    private final WebClient webClient;
    public OpenRouterApi(String openAiToken) {
//        super(openAiToken);
        this(OpenRouterApi.DEFAULT_BASE_URL, openAiToken);
    }

    public OpenRouterApi(String baseUrl, String token) {
//        super(baseUrl, openAiToken);
        this(baseUrl, token, RestClient.builder());
    }

    public OpenRouterApi(String baseUrl, String token, RestClient.Builder restClientBuilder) {
//        super(baseUrl, openAiToken, restClientBuilder);
        this(baseUrl, token, restClientBuilder, RetryUtils.DEFAULT_RESPONSE_ERROR_HANDLER);
    }

    public OpenRouterApi(String baseUrl, String openAiToken, RestClient.Builder restClientBuilder, ResponseErrorHandler responseErrorHandler) {
        super(baseUrl, openAiToken, restClientBuilder, responseErrorHandler);
        this.restClient = restClientBuilder
                .baseUrl(baseUrl)
                .defaultHeaders(ApiUtils.getJsonContentHeaders(openAiToken))
                .defaultStatusHandler(responseErrorHandler)
                .build();

        this.webClient = WebClient.builder()
                .baseUrl(baseUrl)
                .defaultHeaders(ApiUtils.getJsonContentHeaders(openAiToken))
                .build();
    }

    public ResponseEntity<OpenAiApi.ChatCompletion> chatCompletionEntity(ChatCompletionRequest chatRequest) {

        Assert.notNull(chatRequest, "The request body can not be null.");
        Assert.isTrue(!chatRequest.stream(), "Request must set the steam property to false.");

        ResponseEntity<ChatCompletion> entity = this.restClient.post()
                .uri("/v1/chat/completions")
                .body(chatRequest)
                .retrieve()
                .toEntity(ChatCompletion.class);
        return null;
    }


    @JsonInclude(JsonInclude.Include.NON_NULL)
    public record ChatCompletion(
            @JsonProperty("id") String id,
            @JsonProperty("choices") List<OpenAiApi.ChatCompletion.Choice> choices,
            @JsonProperty("created") Long created,
            @JsonProperty("model") String model,
            @JsonProperty("system_fingerprint") String systemFingerprint,
            @JsonProperty("object") String object,
            @JsonProperty("usage") Usage usage) {

        /**
         * Chat completion choice.
         *
         * @param finishReason The reason the model stopped generating tokens.
         * @param index The index of the choice in the list of choices.
         * @param message A chat completion message generated by the model.
         * @param logprobs Log probability information for the choice.
         */
        @JsonInclude(JsonInclude.Include.NON_NULL)
        public record Choice(
                @JsonProperty("finish_reason") ChatCompletionFinishReason finishReason,
                @JsonProperty("index") Integer index,
                @JsonProperty("message") ChatCompletionMessage message,
                @JsonProperty("logprobs") LogProbs logprobs) {

        }
    }

    @JsonInclude(JsonInclude.Include.NON_NULL)
    public record ChatCompletionChunk(
            @JsonProperty("id") String id,
            @JsonProperty("choices") List<OpenAiApi.ChatCompletionChunk.ChunkChoice> choices,
            @JsonProperty("created") Long created,
            @JsonProperty("model") String model,
            @JsonProperty("system_fingerprint") String systemFingerprint,
            @JsonProperty("object") String object) {

        /**
         * Chat completion choice.
         *
         * @param finishReason The reason the model stopped generating tokens.
         * @param index The index of the choice in the list of choices.
         * @param delta A chat completion delta generated by streamed model responses.
         * @param logprobs Log probability information for the choice.
         */
        @JsonInclude(JsonInclude.Include.NON_NULL)
        public record ChunkChoice(
                @JsonProperty("finish_reason") ChatCompletionFinishReason finishReason,
                @JsonProperty("index") Integer index,
                @JsonProperty("delta") ChatCompletionMessage delta,
                @JsonProperty("logprobs") LogProbs logprobs) {
        }
    }
    /**
     * The reason the model stopped generating tokens.
     */
    public enum ChatCompletionFinishReason {
        /**
         * The model hit a natural stop point or a provided stop sequence.
         */
        @JsonProperty("stop") STOP,
        /**
         * The maximum number of tokens specified in the request was reached.
         */
        @JsonProperty("length") LENGTH,
        /**
         * The content was omitted due to a flag from our content filters.
         */
        @JsonProperty("content_filter") CONTENT_FILTER,
        /**
         * The model called a tool.
         */
        @JsonProperty("tool_calls") TOOL_CALLS,
        /**
         * (deprecated) The model called a function.
         */
        @JsonProperty("function_call") FUNCTION_CALL,
        /**
         * Only for compatibility with Mistral AI API.
         */
        @JsonProperty("tool_call") TOOL_CALL,
        /**
         * 新增的一种情况
         */
        @JsonProperty("eos") EOS
    }
}
